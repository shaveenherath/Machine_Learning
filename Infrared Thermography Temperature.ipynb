{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gender', 'Age', 'Ethnicity', 'T_atm', 'Humidity', 'Distance',\n",
      "       'T_offset1', 'Max1R13_1', 'Max1L13_1', 'aveAllR13_1', 'aveAllL13_1',\n",
      "       'T_RC1', 'T_RC_Dry1', 'T_RC_Wet1', 'T_RC_Max1', 'T_LC1', 'T_LC_Dry1',\n",
      "       'T_LC_Wet1', 'T_LC_Max1', 'RCC1', 'LCC1', 'canthiMax1', 'canthi4Max1',\n",
      "       'T_FHCC1', 'T_FHRC1', 'T_FHLC1', 'T_FHBC1', 'T_FHTC1', 'T_FH_Max1',\n",
      "       'T_FHC_Max1', 'T_Max1', 'T_OR1', 'T_OR_Max1'],\n",
      "      dtype='object')\n",
      "Index(['aveOralF', 'aveOralM'], dtype='object')\n",
      "   Gender    Age                  Ethnicity  T_atm  Humidity  Distance  \\\n",
      "0    Male  41-50                      White   24.0      28.0       0.8   \n",
      "1  Female  31-40  Black or African-American   24.0      26.0       0.8   \n",
      "2  Female  21-30                      White   24.0      26.0       0.8   \n",
      "3  Female  21-30  Black or African-American   24.0      27.0       0.8   \n",
      "4    Male  18-20                      White   24.0      27.0       0.8   \n",
      "\n",
      "   T_offset1  Max1R13_1  Max1L13_1  aveAllR13_1  ...  T_FHCC1  T_FHRC1  \\\n",
      "0     0.7025    35.0300    35.3775      34.4000  ...  33.5775  33.4775   \n",
      "1     0.7800    34.5500    34.5200      33.9300  ...  34.0325  34.0550   \n",
      "2     0.8625    35.6525    35.5175      34.2775  ...  34.9000  34.8275   \n",
      "3     0.9300    35.2225    35.6125      34.3850  ...  34.4400  34.4225   \n",
      "4     0.8950    35.5450    35.6650      34.9100  ...  35.0900  35.1600   \n",
      "\n",
      "   T_FHLC1  T_FHBC1  T_FHTC1  T_FH_Max1  T_FHC_Max1   T_Max1    T_OR1  \\\n",
      "0  33.3725  33.4925  33.0025    34.5300     34.0075  35.6925  35.6350   \n",
      "1  33.6775  33.9700  34.0025    34.6825     34.6600  35.1750  35.0925   \n",
      "2  34.6475  34.8200  34.6700    35.3450     35.2225  35.9125  35.8600   \n",
      "3  34.6550  34.3025  34.9175    35.6025     35.3150  35.7200  34.9650   \n",
      "4  34.3975  34.6700  33.8275    35.4175     35.3725  35.8950  35.5875   \n",
      "\n",
      "   T_OR_Max1  \n",
      "0    35.6525  \n",
      "1    35.1075  \n",
      "2    35.8850  \n",
      "3    34.9825  \n",
      "4    35.6175  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "   aveOralF  aveOralM\n",
      "0     36.85     36.59\n",
      "1     37.00     37.19\n",
      "2     37.20     37.34\n",
      "3     36.85     37.09\n",
      "4     36.80     37.04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fetch dataset\n",
    "infrared_thermography_temperature = fetch_ucirepo(id=925)\n",
    "\n",
    "# Convert data to pandas DataFrame\n",
    "X = pd.DataFrame(infrared_thermography_temperature.data.features)\n",
    "y = pd.DataFrame(infrared_thermography_temperature.data.targets)\n",
    "                \n",
    "\n",
    "\n",
    "# Display all column names in the DataFrame\n",
    "print(X.columns)\n",
    "print(y.columns)\n",
    "\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(X.head())\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts of missing values in each feature column:\n",
      "Gender         0\n",
      "Age            0\n",
      "Ethnicity      0\n",
      "T_atm          0\n",
      "Humidity       0\n",
      "Distance       2\n",
      "T_offset1      0\n",
      "Max1R13_1      0\n",
      "Max1L13_1      0\n",
      "aveAllR13_1    0\n",
      "aveAllL13_1    0\n",
      "T_RC1          0\n",
      "T_RC_Dry1      0\n",
      "T_RC_Wet1      0\n",
      "T_RC_Max1      0\n",
      "T_LC1          0\n",
      "T_LC_Dry1      0\n",
      "T_LC_Wet1      0\n",
      "T_LC_Max1      0\n",
      "RCC1           0\n",
      "LCC1           0\n",
      "canthiMax1     0\n",
      "canthi4Max1    0\n",
      "T_FHCC1        0\n",
      "T_FHRC1        0\n",
      "T_FHLC1        0\n",
      "T_FHBC1        0\n",
      "T_FHTC1        0\n",
      "T_FH_Max1      0\n",
      "T_FHC_Max1     0\n",
      "T_Max1         0\n",
      "T_OR1          0\n",
      "T_OR_Max1      0\n",
      "dtype: int64\n",
      "\n",
      "Counts of missing values in the target column:\n",
      "aveOralF    0\n",
      "aveOralM    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the features DataFrame (X)\n",
    "missing_values_features = X.isnull()\n",
    "\n",
    "# Count missing values in each feature column\n",
    "missing_counts_features = X.isnull().sum()\n",
    "\n",
    "# Display the counts of missing values in each feature column\n",
    "print(\"\\nCounts of missing values in each feature column:\")\n",
    "print(missing_counts_features)\n",
    "\n",
    "# Check for missing values in the target DataFrame (y)\n",
    "missing_values_target = y.isnull()\n",
    "\n",
    "# Count missing values in the target column\n",
    "missing_counts_target = y.isnull().sum()\n",
    "\n",
    "# Display the counts of missing values in the target column\n",
    "print(\"\\nCounts of missing values in the target column:\")\n",
    "print(missing_counts_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the features DataFrame (X)\n",
    "X_cleaned = X.dropna()\n",
    "\n",
    "# Drop rows with missing values in the target DataFrame (y)\n",
    "y_cleaned = y.dropna()\n",
    "\n",
    "# Ensure that both DataFrames have the same indices\n",
    "# Align indices before dropping rows\n",
    "common_indices = X_cleaned.index.intersection(y_cleaned.index)\n",
    "X_cleaned = X_cleaned.loc[common_indices]\n",
    "y_cleaned = y_cleaned.loc[common_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts of missing values in each feature column after cleaning:\n",
      "Gender         0\n",
      "Age            0\n",
      "Ethnicity      0\n",
      "T_atm          0\n",
      "Humidity       0\n",
      "Distance       0\n",
      "T_offset1      0\n",
      "Max1R13_1      0\n",
      "Max1L13_1      0\n",
      "aveAllR13_1    0\n",
      "aveAllL13_1    0\n",
      "T_RC1          0\n",
      "T_RC_Dry1      0\n",
      "T_RC_Wet1      0\n",
      "T_RC_Max1      0\n",
      "T_LC1          0\n",
      "T_LC_Dry1      0\n",
      "T_LC_Wet1      0\n",
      "T_LC_Max1      0\n",
      "RCC1           0\n",
      "LCC1           0\n",
      "canthiMax1     0\n",
      "canthi4Max1    0\n",
      "T_FHCC1        0\n",
      "T_FHRC1        0\n",
      "T_FHLC1        0\n",
      "T_FHBC1        0\n",
      "T_FHTC1        0\n",
      "T_FH_Max1      0\n",
      "T_FHC_Max1     0\n",
      "T_Max1         0\n",
      "T_OR1          0\n",
      "T_OR_Max1      0\n",
      "dtype: int64\n",
      "\n",
      "Counts of missing values in the target column after cleaning:\n",
      "aveOralF    0\n",
      "aveOralM    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the features DataFrame (X_cleaned)\n",
    "missing_values_features_cleaned = X_cleaned.isnull()\n",
    "\n",
    "# Count missing values in each feature column after cleaning\n",
    "missing_counts_features_cleaned = X_cleaned.isnull().sum()\n",
    "\n",
    "# Display the counts of missing values in each feature column after cleaning\n",
    "print(\"\\nCounts of missing values in each feature column after cleaning:\")\n",
    "print(missing_counts_features_cleaned)\n",
    "\n",
    "# Check for missing values in the target DataFrame (y_cleaned)\n",
    "missing_values_target_cleaned = y_cleaned.isnull()\n",
    "\n",
    "# Count missing values in the target column after cleaning\n",
    "missing_counts_target_cleaned = y_cleaned.isnull().sum()\n",
    "\n",
    "# Display the counts of missing values in the target column after cleaning\n",
    "print(\"\\nCounts of missing values in the target column after cleaning:\")\n",
    "print(missing_counts_target_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_groups :  ['41-50' '31-40' '21-30' '18-20' '26-30' '21-25' '>60' '51-60']\n"
     ]
    }
   ],
   "source": [
    "age_groups = X[\"Age\"].unique()\n",
    "print(\"age_groups : \", age_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Gender                  Ethnicity  T_atm  Humidity  Distance  T_offset1  \\\n",
      "0       Male                      White   24.0      28.0       0.8     0.7025   \n",
      "1     Female  Black or African-American   24.0      26.0       0.8     0.7800   \n",
      "2     Female                      White   24.0      26.0       0.8     0.8625   \n",
      "3     Female  Black or African-American   24.0      27.0       0.8     0.9300   \n",
      "4       Male                      White   24.0      27.0       0.8     0.8950   \n",
      "...      ...                        ...    ...       ...       ...        ...   \n",
      "1015  Female                      Asian   25.7      50.8       0.6     1.2225   \n",
      "1016  Female                      White   25.7      50.8       0.6     1.4675   \n",
      "1017  Female  Black or African-American   28.0      24.3       0.6     0.1300   \n",
      "1018    Male            Hispanic/Latino   25.0      39.8       0.6     1.2450   \n",
      "1019  Female                      White   23.8      45.6       0.6     0.8675   \n",
      "\n",
      "      Max1R13_1  Max1L13_1  aveAllR13_1  aveAllL13_1  ...   T_Max1    T_OR1  \\\n",
      "0       35.0300    35.3775      34.4000      34.9175  ...  35.6925  35.6350   \n",
      "1       34.5500    34.5200      33.9300      34.2250  ...  35.1750  35.0925   \n",
      "2       35.6525    35.5175      34.2775      34.8000  ...  35.9125  35.8600   \n",
      "3       35.2225    35.6125      34.3850      35.2475  ...  35.7200  34.9650   \n",
      "4       35.5450    35.6650      34.9100      35.3675  ...  35.8950  35.5875   \n",
      "...         ...        ...          ...          ...  ...      ...      ...   \n",
      "1015    35.6425    35.6525      34.8575      35.0050  ...  36.0675  35.6775   \n",
      "1016    35.9825    35.7575      35.4275      35.1975  ...  36.5000  36.4525   \n",
      "1017    36.4075    36.3400      35.8700      35.9600  ...  36.5350  35.9650   \n",
      "1018    35.8150    35.5250      34.2950      34.0100  ...  35.8600  35.4150   \n",
      "1019    35.7075    35.5825      34.8875      35.0875  ...  35.9725  35.8900   \n",
      "\n",
      "      T_OR_Max1  Age_21-25  Age_21-30  Age_26-30  Age_31-40  Age_41-50  \\\n",
      "0       35.6525      False      False      False      False       True   \n",
      "1       35.1075      False      False      False       True      False   \n",
      "2       35.8850      False       True      False      False      False   \n",
      "3       34.9825      False       True      False      False      False   \n",
      "4       35.6175      False      False      False      False      False   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1015    35.7100       True      False      False      False      False   \n",
      "1016    36.4900       True      False      False      False      False   \n",
      "1017    35.9975      False      False      False      False      False   \n",
      "1018    35.4350      False      False       True      False      False   \n",
      "1019    35.9175      False      False      False      False      False   \n",
      "\n",
      "      Age_51-60  Age_>60  \n",
      "0         False    False  \n",
      "1         False    False  \n",
      "2         False    False  \n",
      "3         False    False  \n",
      "4         False    False  \n",
      "...         ...      ...  \n",
      "1015      False    False  \n",
      "1016      False    False  \n",
      "1017      False    False  \n",
      "1018      False    False  \n",
      "1019      False    False  \n",
      "\n",
      "[1020 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoding to the 'Age' column\n",
    "X_encoded = pd.get_dummies(X, columns=['Age'], drop_first=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male' 'Female']\n",
      "      Gender   Age                  Ethnicity  T_atm  Humidity  Distance  \\\n",
      "0          1  45.5                      White   24.0      28.0       0.8   \n",
      "1          0  35.5  Black or African-American   24.0      26.0       0.8   \n",
      "2          0  25.5                      White   24.0      26.0       0.8   \n",
      "3          0  25.5  Black or African-American   24.0      27.0       0.8   \n",
      "4          1  19.0                      White   24.0      27.0       0.8   \n",
      "...      ...   ...                        ...    ...       ...       ...   \n",
      "1015       0  23.0                      Asian   25.7      50.8       0.6   \n",
      "1016       0  23.0                      White   25.7      50.8       0.6   \n",
      "1017       0  19.0  Black or African-American   28.0      24.3       0.6   \n",
      "1018       1  28.0            Hispanic/Latino   25.0      39.8       0.6   \n",
      "1019       0  19.0                      White   23.8      45.6       0.6   \n",
      "\n",
      "      T_offset1  Max1R13_1  Max1L13_1  aveAllR13_1  ...  T_FHCC1  T_FHRC1  \\\n",
      "0        0.7025    35.0300    35.3775      34.4000  ...  33.5775  33.4775   \n",
      "1        0.7800    34.5500    34.5200      33.9300  ...  34.0325  34.0550   \n",
      "2        0.8625    35.6525    35.5175      34.2775  ...  34.9000  34.8275   \n",
      "3        0.9300    35.2225    35.6125      34.3850  ...  34.4400  34.4225   \n",
      "4        0.8950    35.5450    35.6650      34.9100  ...  35.0900  35.1600   \n",
      "...         ...        ...        ...          ...  ...      ...      ...   \n",
      "1015     1.2225    35.6425    35.6525      34.8575  ...  35.1075  35.3475   \n",
      "1016     1.4675    35.9825    35.7575      35.4275  ...  35.3100  35.2175   \n",
      "1017     0.1300    36.4075    36.3400      35.8700  ...  35.4350  35.2400   \n",
      "1018     1.2450    35.8150    35.5250      34.2950  ...  34.8400  35.0200   \n",
      "1019     0.8675    35.7075    35.5825      34.8875  ...  34.5475  34.6500   \n",
      "\n",
      "      T_FHLC1  T_FHBC1  T_FHTC1  T_FH_Max1  T_FHC_Max1   T_Max1    T_OR1  \\\n",
      "0     33.3725  33.4925  33.0025    34.5300     34.0075  35.6925  35.6350   \n",
      "1     33.6775  33.9700  34.0025    34.6825     34.6600  35.1750  35.0925   \n",
      "2     34.6475  34.8200  34.6700    35.3450     35.2225  35.9125  35.8600   \n",
      "3     34.6550  34.3025  34.9175    35.6025     35.3150  35.7200  34.9650   \n",
      "4     34.3975  34.6700  33.8275    35.4175     35.3725  35.8950  35.5875   \n",
      "...       ...      ...      ...        ...         ...      ...      ...   \n",
      "1015  35.4000  35.1375  35.2750    35.8525     35.7475  36.0675  35.6775   \n",
      "1016  35.2200  35.2075  35.0700    35.7650     35.5525  36.5000  36.4525   \n",
      "1017  35.2275  35.3675  35.3425    36.3750     35.7100  36.5350  35.9650   \n",
      "1018  34.9250  34.7150  34.5950    35.4150     35.3100  35.8600  35.4150   \n",
      "1019  34.6700  34.2150  34.7100    35.1525     35.1175  35.9725  35.8900   \n",
      "\n",
      "      T_OR_Max1  \n",
      "0       35.6525  \n",
      "1       35.1075  \n",
      "2       35.8850  \n",
      "3       34.9825  \n",
      "4       35.6175  \n",
      "...         ...  \n",
      "1015    35.7100  \n",
      "1016    36.4900  \n",
      "1017    35.9975  \n",
      "1018    35.4350  \n",
      "1019    35.9175  \n",
      "\n",
      "[1020 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to convert age range\n",
    "def convert_age_range(age_range):\n",
    "    \"\"\"Converts the age range to a single average value\"\"\"\n",
    "    if isinstance(age_range, str):\n",
    "        if '>' in age_range:\n",
    "            return int(age_range.replace('>', '').strip())\n",
    "        lower, upper = map(int, age_range.split('-'))\n",
    "        return np.mean([lower, upper])\n",
    "    return age_range  # Return the value as is if it's not a string\n",
    "\n",
    "# Apply the function to the 'Age' column\n",
    "X['Age'] = X['Age'].apply(convert_age_range)\n",
    "\n",
    "# Check unique values in the 'Gender' column\n",
    "print(X['Gender'].unique())\n",
    "\n",
    "# Convert 'Gender' column to numeric\n",
    "X['Gender'] = X['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Age       Gender        T_atm     Humidity    T_offset1\n",
      "count  1020.000000  1020.000000  1020.000000  1020.000000  1020.000000\n",
      "mean     22.296569     0.405882    24.115392    28.723039     0.968648\n",
      "std       5.852500     0.491303     1.336338    13.071627     0.362587\n",
      "min      19.000000     0.000000    20.200000     9.900000    -0.590000\n",
      "25%      19.000000     0.000000    23.400000    17.600000     0.772500\n",
      "50%      19.000000     0.000000    24.000000    26.300000     0.940000\n",
      "75%      23.000000     1.000000    24.700000    36.200000     1.140000\n",
      "max      60.000000     1.000000    29.100000    61.200000     2.875000\n",
      "          aveOralM\n",
      "count  1020.000000\n",
      "mean     37.028382\n",
      "std       0.509502\n",
      "min      35.540000\n",
      "25%      36.777500\n",
      "50%      36.940000\n",
      "75%      37.140000\n",
      "max      40.340000\n"
     ]
    }
   ],
   "source": [
    "# Select the relevant columns\n",
    "selected_columns_X = ['Age', 'Gender', 'T_atm', 'Humidity', 'T_offset1']\n",
    "selected_columns_y = ['aveOralM']\n",
    "\n",
    "# Get the statistical summary\n",
    "statistical_details_X = X[selected_columns_X].describe()\n",
    "statistical_details_y = y[selected_columns_y].describe()\n",
    "\n",
    "\n",
    "# Display the statistical details\n",
    "print(statistical_details_X)\n",
    "print(statistical_details_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 36.62796301934947\n",
      "     Feature  Coefficient\n",
      "0        Age    -0.008195\n",
      "1     Gender     0.066194\n",
      "2      T_atm     0.015053\n",
      "3   Humidity     0.001640\n",
      "4  T_offset1     0.148206\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming X_new and y_new are already defined with the selected columns\n",
    "X_new = X[['Age', 'Gender', 'T_atm', 'Humidity', 'T_offset1']]\n",
    "y_new = y['aveOralM']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Estimate the coefficients corresponding to the independent variables\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Create a DataFrame to display the coefficients alongside the feature names\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': X_new.columns,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Display the estimated intercept & coefficients \n",
    "print('Intercept: \\n', model.intercept_)\n",
    "print(coefficients_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 7.036879763545965\n",
      "      Feature  Coefficient\n",
      "0       T_OR1     0.091997\n",
      "1   T_OR_Max1     0.464070\n",
      "2  T_FHC_Max1    -0.087332\n",
      "3   T_FH_Max1     0.370886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the independent features and the dependent feature\n",
    "independent_features = ['T_OR1', 'T_OR_Max1', 'T_FHC_Max1', 'T_FH_Max1']\n",
    "X1 = X[independent_features]\n",
    "y1 = y['aveOralM']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Estimate the coefficients corresponding to the independent variables\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Create a DataFrame to display the coefficients alongside the feature names\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': independent_features,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Display the estimated coefficients\n",
    "print('Intercept: \\n', model.intercept_)\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Sum of Squares (RSS): 15.170504359408241\n",
      "Residual Standard Error (RSE): 0.2761044915394942\n",
      "Mean Squared Error (MSE): 0.07436521744807961\n",
      "R-squared (R²): 0.646842080055587\n",
      "\n",
      "Feature Statistics:\n",
      "        Feature  Coefficient  Standard Error  t-Statistic   p-Value\n",
      "x1       T_OR1     0.091997        1.624156     0.828232  0.408531\n",
      "x2   T_OR_Max1     0.464070        1.619382    -0.507885  0.612096\n",
      "x3  T_FHC_Max1    -0.087332        0.081987     0.534191  0.593806\n",
      "x4   T_FH_Max1     0.370886        0.090514     2.284496  0.023397\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Residual Sum of Squares (RSS)\n",
    "residual_sum_of_squares = np.sum((y_pred - y_test) ** 2)\n",
    "\n",
    "# Calculate Residual Standard Error (RSE)\n",
    "n = X_test.shape[0]\n",
    "d = X_test.shape[1]\n",
    "residual_standard_error = np.sqrt(residual_sum_of_squares / (n - d - 1))\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mean_squared_error_value = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate R-squared (R²)\n",
    "r_squared = model.score(X_test, y_test)\n",
    "\n",
    "# Prepare data for OLS model to get additional statistics\n",
    "X_test_with_intercept = np.c_[np.ones(X_test.shape[0]), X_test]  # Add constant term\n",
    "ols_model = sm.OLS(y_test, X_test_with_intercept).fit()\n",
    "\n",
    "# Extract statistics from the OLS model\n",
    "standard_errors = ols_model.bse[1:]  # Exclude the intercept term\n",
    "t_values = ols_model.tvalues[1:]  # Exclude the intercept term\n",
    "p_values = ols_model.pvalues[1:]  # Exclude the intercept term\n",
    "\n",
    "# Display results\n",
    "print(f\"Residual Sum of Squares (RSS): {residual_sum_of_squares}\")\n",
    "print(f\"Residual Standard Error (RSE): {residual_standard_error}\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error_value}\")\n",
    "print(f\"R-squared (R²): {r_squared}\")\n",
    "\n",
    "# Create a DataFrame to display feature statistics\n",
    "results_df = pd.DataFrame({\n",
    "    'Feature': independent_features,\n",
    "    'Coefficient': model.coef_,\n",
    "    'Standard Error': standard_errors,\n",
    "    't-Statistic': t_values,\n",
    "    'p-Value': p_values\n",
    "})\n",
    "\n",
    "print(\"\\nFeature Statistics:\\n\", results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
